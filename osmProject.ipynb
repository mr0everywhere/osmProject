{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23df4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import gc\n",
    "import csv\n",
    "import codecs \n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from humanize import naturalsize\n",
    "import requests\n",
    "\n",
    "# Declare Variables\n",
    "\n",
    "\n",
    "OSM_FILE = \"Phoenix.osm\" # Total set of about 34M\n",
    "SAMPLE_FILE = \"phxsmall.osm\" # small subset about  3.4K\n",
    "TEST_FILE=\"phxmed.osm\" #intermediate subset about 340K \n",
    "     # get osm data for project\n",
    "url = \"http://overpass-api.de/api/interpreter?data=%28node%2832%2E6020062%2C%2D112%2E9699853%2C34%2E318%2C%2D111%2E036001%29%3B%3C%3B%29%3Bout%20meta%3B%0A\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('Phoenix.osm', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\",\"Way\", \"Circle\", \"Key\",\"Terrace\", \"Garden\"]\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\":\"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"BLVD\": \"Boulevard\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"PL\": \"Place\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"Ln\":\"Lane\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Cir\": \"Circle\",\n",
    "            \"Dr\": \"Drive\"\n",
    "          }\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15fbf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()})\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "def audit_address(filename):\n",
    "    expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \"Trail\", \"Parkway\", \"Commons\", \"Way\", \"Circle\", \"Key\", \"Terrace\", \"Garden\"]\n",
    "    street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "    postcode_key = 'addr:postcode'\n",
    "    street_key = 'addr:postcode'\n",
    "    state_key = 'addr:state'\n",
    "    city_key = 'addr:state'\n",
    "    county_key = 'addr:county'\n",
    "    \n",
    "    postcode_types = {}\n",
    "    street_types = {}\n",
    "    state_types = {}\n",
    "    city_types = {}\n",
    "    county_types = {}\n",
    "    \n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k']== postcode_key:\n",
    "                    if not re.search(r\"^8[56]\\d{3}-?(\\d{4})?$\", tag.attrib['v']):\n",
    "                        if tag.attrib['v'] in postcode_types:\n",
    "                            postcode_types[tag.attrib['v']]+=1\n",
    "                        else:\n",
    "                            postcode_types[tag.attrib['v']]=1\n",
    "                elif tag.attrib['k']== street_key:\n",
    "                    m = street_type_re.search(tag.attrib['v'])\n",
    "                    if m:\n",
    "                        street_type = m.group()\n",
    "                        if street_type not in expected:\n",
    "                            street_types[street_type]=street_types.get(street_type,0)+1\n",
    "                elif tag.attrib['k']==state_key:\n",
    "                    state_types[tag.attrib['v']]=state_types.get(tag.attrib['v'],0)+1\n",
    "                elif tag.attrib['k']==city_key:\n",
    "                    city_types[tag.attrib['v']]=city_types.get(tag.attrib['v'],0)+1\n",
    "                elif tag.attrib['k']==county_key:\n",
    "                    county_types[tag.attrib['v']]=county_types.get(tag.attrib['v'],0)+1\n",
    "                    \n",
    "    print '\\nPostcodes out of norm:\\n', postcode_types, '\\nStreets out of norm:\\n', street_types, '\\nStates:\\n', state_types, '\\nCities:\\n', city_types, '\\nCounties:\\n', county_types\n",
    "            \n",
    "            \n",
    "def update_name(name, mapping):\n",
    "    street=street_type_re.search(name).group()\n",
    "\n",
    "    name=name.replace(street, mapping[street])\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "#clean_element function take tag['value'] and tag['key'] as input and return the updated tag values \n",
    "def clean_element(tag_value, tag_key):\n",
    "    \n",
    "    ## clean postcode \n",
    "    if tag_key=='postcode':\n",
    "        if tag_value[0:2]!='85' or len(tag_value)!=5:\n",
    "            ## find postcode start with 'AZ' and remove the 'AZ' \n",
    "            if tag_value[0:2]=='AZ': \n",
    "                    tag_value=tag_value[-5:]\n",
    "     \n",
    "                    #print (tag_value)\n",
    "                            \n",
    "            ##  find cases that using full address as postcode and extract the postcode using re module\n",
    "            else:\n",
    "                if len(tag_value)>5:\n",
    "                    #print(tag.attrib['v'])\n",
    "                    pc=re.search('(85\\d{3})', tag_value)\n",
    "                    if pc:\n",
    "                        tag_value=pc.group()\n",
    "              \n",
    "    ## clean state name, use uniformat 'AZ'       \n",
    "    elif tag_key=='state':\n",
    "        tag_value='AZ'\n",
    "        \n",
    "    ## clean street suffix, change abbrivations to full street suffix        \n",
    "    elif tag_key=='street':\n",
    "        street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "        full_addr=tag_value\n",
    "        m = street_type_re.search(full_addr)\n",
    "        if m:\n",
    "            street_type = m.group() \n",
    "            if street_type not in expected:\n",
    "                if street_type in mapping:\n",
    "                    tag_value=update_name(full_addr, mapping)\n",
    "    return tag_value\n",
    "                             \n",
    "## Clean and shape node or way XML element to Python dict\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "   \n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "   \n",
    "    ## clean node element\n",
    "    if element.tag=='node':\n",
    "        for primary in element.iter():\n",
    "            for i in node_attr_fields: \n",
    "                if i in primary.attrib: \n",
    "                    node_attribs[i]=primary.attrib[i]\n",
    "        if len(element)!=0:\n",
    "            for j in range(0, len(element)): \n",
    "                childelem=element[j]\n",
    "                tag={}\n",
    "                if not problem_chars.search(childelem.attrib['k']): ## ignor problematic element\n",
    "                    tag[\"id\"]=element.attrib[\"id\"]\n",
    "                    tag[\"type\"]=default_tag_type\n",
    "                    tag['value']=childelem.attrib['v']\n",
    "                    if \":\" in childelem.attrib['k']:\n",
    "                        k_and_v=childelem.attrib['k'].split(':',1)\n",
    "                        tag[\"type\"]=k_and_v[0]\n",
    "                        tag[\"key\"]=k_and_v[1]\n",
    "                        if tag[\"type\"]=='addr':\n",
    "                            tag[\"value\"]=clean_element(tag[\"value\"],tag[\"key\"]) ## call clean_element function\n",
    "                    else:\n",
    "                        tag[\"key\"]=childelem.attrib['k']\n",
    "                        if tag[\"type\"]=='addr':\n",
    "                            print(tag_value, tag[\"key\"])\n",
    "                            tag[\"value\"]=clean_element(tag[\"value\"],tag[\"key\"])\n",
    "                tags.append(tag)\n",
    "                \n",
    "        return ({'node': node_attribs, 'node_tags': tags})            \n",
    "                    \n",
    "    ## handle way element               \n",
    "    elif element.tag=='way':\n",
    "        for primary in element.iter():\n",
    "            for i in way_attr_fields: \n",
    "                if i in primary.attrib: \n",
    "                    way_attribs[i]=primary.attrib[i]   \n",
    "        \n",
    "        if len(element)!=0: \n",
    "            for j in range(0, len(element)): \n",
    "                childelem=element[j]\n",
    "                tag={}\n",
    "                if childelem.tag=='tag':\n",
    "                    if not problem_chars.search(childelem.attrib['k']):\n",
    "                        tag[\"id\"]=element.attrib[\"id\"]\n",
    "                        tag[\"type\"]=default_tag_type\n",
    "                        tag[\"value\"]=childelem.attrib['v']\n",
    "                        if \":\" in childelem.attrib['k']:\n",
    "                            k_and_v=childelem.attrib['k'].split(':',1)\n",
    "                            tag[\"key\"]=k_and_v[1]\n",
    "                            tag[\"type\"]=k_and_v[0]\n",
    "                            if tag[\"type\"]=='addr':\n",
    "                                tag[\"value\"]=clean_element(tag[\"value\"],tag[\"key\"]) #call clean_element function\n",
    "                        else:\n",
    "                            tag[\"key\"]=childelem.attrib['k']\n",
    "                            if tag[\"type\"]=='addr':\n",
    "                                tag[\"value\"]=clean_element(tag[\"value\"],tag[\"key\"]) #update tag values\n",
    "                    tags.append(tag)\n",
    "                    \n",
    "                elif childelem.tag=='nd':\n",
    "                    #print (childelem.attrib['ref'])\n",
    "                    way_node={}\n",
    "                    way_node['id']=element.attrib['id'] \n",
    "                    way_node['node_id']=childelem.attrib['ref']\n",
    "                    way_node['position']=j\n",
    "                    #print(way_node)\n",
    "                    way_nodes.append(way_node)\n",
    "                    \n",
    "        return ({'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags})\n",
    "    \n",
    "\n",
    "## process the file, clean and write XML into csv\n",
    "\n",
    "def process_map(file_in):\n",
    "    with codecs.open(NODES_PATH, 'wb') as nodes_file, codecs.open(NODE_TAGS_PATH, 'wb') as nodes_tags_file, codecs.open(WAYS_PATH, 'wb') as ways_file, codecs.open(WAY_NODES_PATH, 'wb') as way_nodes_file, codecs.open(WAY_TAGS_PATH, 'wb') as way_tags_file:\n",
    "                \n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "        \n",
    "        nodes_writer.writeheader()\n",
    "        \n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "       \n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "                    \n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()         \n",
    "            \n",
    "## create samples of original osm\n",
    "def sample_data (large, small, medium): \n",
    "    \n",
    "    k = 10000 # Parameter: take every k-th top level element, take small sample\n",
    "    m = 100 # take intermediate sample  \n",
    "    with open(small, 'wb') as output1, open(medium,'wb') as output2:\n",
    "        output1.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "        output1.write('<osm>\\n  ')\n",
    "        output2.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "        output2.write('<osm>\\n  ')\n",
    "    # Write every kth and mth top level element\n",
    "        for i, element in enumerate(get_element(large)):\n",
    "            if i % k == 0:\n",
    "                output1.write(str(ET.tostring(element, encoding='utf-8')))\n",
    "                output2.write(str(ET.tostring(element, encoding='utf-8')))\n",
    "            elif i % m == 0:\n",
    "                output2.write(str(ET.tostring(element, encoding='utf-8')))\n",
    "        output1.write('</osm>')\n",
    "        output2.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a738cd-abbe-472c-901e-1f2452888841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_data(OSM_FILE, SAMPLE_FILE,TEST_FILE)\n",
    "# audit_address(SAMPLE_FILE)\n",
    "# audit_address(TEST_FILE)\n",
    "# audit_address(OSM_FILE)\n",
    "process_map(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08db785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create database from text files\n",
    "if os.path.isfile('phoenix.db'):\n",
    "    os.remove('phoenix.db')\n",
    "conn=sqlite3.connect('phoenix.db')\n",
    "conn.text_factory = lambda x: unicode(x, 'utf-8', 'ignore') #added to fix an error showing extra spaces and then not being able to laod into the db\n",
    "cur = conn.cursor() \n",
    "cur.execute(\"CREATE TABLE nodes ( id INTEGER PRIMARY KEY NOT NULL, lat REAL, lon REAL, user TEXT, uid INTEGER, version INTEGER, changeset INTEGER, timestamp TEXT )\")\n",
    "conn.commit()\n",
    "node_df = pd.read_csv('nodes.csv', dtype=object)\n",
    "node_df.to_sql('nodes', conn, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "cur.execute(\"CREATE TABLE nodes_tags (id INTEGER,\\\n",
    "    key TEXT,\\\n",
    "    value TEXT,\\\n",
    "    type TEXT,\\\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\\\n",
    ")\")\n",
    "conn.commit()\n",
    "nodetag_df=pd.read_csv('nodes_tags.csv')\n",
    "nodetag_df.to_sql('nodes_tags', conn, if_exists='append', index=False)\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways (\\\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\\\n",
    "    user TEXT,\\\n",
    "    uid INTEGER,\\\n",
    "    version TEXT,\\\n",
    "    changeset INTEGER,\\\n",
    "    timestamp TEXT\\\n",
    ")\")\n",
    "conn.commit()\n",
    "way_df=pd.read_csv('ways.csv')\n",
    "way_df.to_sql('ways', conn, if_exists='append', index=False)\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways_nodes (\\\n",
    "    id INTEGER NOT NULL,\\\n",
    "    node_id INTEGER NOT NULL, \\\n",
    "    position INTEGER NOT NULL, \\\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\\\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id)\\\n",
    ")\")\n",
    "conn.commit()\n",
    "waynode_df=pd.read_csv('ways_nodes.csv')\n",
    "waynode_df.to_sql('ways_nodes', conn, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways_tags (\\\n",
    "    id INTEGER NOT NULL,\\\n",
    "    key TEXT NOT NULL,\\\n",
    "    value TEXT NOT NULL,\\\n",
    "    type TEXT,\\\n",
    "    FOREIGN KEY (id) REFERENCES ways(id)\\\n",
    ")\")\n",
    "conn.commit()\n",
    "waytag_df=pd.read_csv('ways_tags.csv')\n",
    "waytag_df=waytag_df.dropna(subset=['id', 'key', 'value'], how='any')\n",
    "waytag_df.to_sql('ways_tags', conn, if_exists='append', index=False)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9f88b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('osmProject-checkpoint.ipynb', '37.0 kB')\n",
      "('nodes.csv', '988.5 MB')\n",
      "('nodes_tags.csv', '28.5 MB')\n",
      "('phoenix.db', '1.5 GB')\n",
      "('Phoenix.osm', '2.7 GB')\n",
      "('phoenix2.osm', '0 Bytes')\n",
      "('phx2.osm', '39.5 MB')\n",
      "('phx3.osm', '2.7 GB')\n",
      "('phxmed.osm', '27.4 MB')\n",
      "('phxsmall.osm', '302.6 kB')\n",
      "('ways.csv', '101.3 MB')\n",
      "('ways_nodes.csv', '325.4 MB')\n",
      "('ways_tags.csv', '240.0 MB')\n",
      "('nodes.csv', '989.9 MB')\n",
      "('nodes_tags.csv', '28.6 MB')\n",
      "('osmProject.ipynb', '23.3 kB')\n",
      "('phoenix.db', '1.5 GB')\n",
      "('Phoenix.osm', '2.7 GB')\n",
      "('phxmed.osm', '27.4 MB')\n",
      "('phxsmall.osm', '270.4 kB')\n",
      "('ways.csv', '101.4 MB')\n",
      "('ways_nodes.csv', '325.8 MB')\n",
      "('ways_tags.csv', '239.9 MB')\n"
     ]
    }
   ],
   "source": [
    "directory = os.getcwd()\n",
    "for root, dirs, files in os.walk(directory, topdown=False):\n",
    "    for name in files:\n",
    "        f = os.path.join(root, name)\n",
    "        print (name, naturalsize(os.path.getsize(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a5b747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in database: 11456335\n",
      "Ways in database: 1648767\n",
      "Nodes Tags in database: 763810\n",
      "Ways Nodes in database: 13518908\n",
      "Ways Tags in database: 6645069\n",
      "\n",
      "Total Rows in database:\u001b[1m 34032889 \u001b[0m\n",
      "\n",
      "Total users that contributed:  3437\n",
      "\n",
      "The top 10 contributors:\n",
      "(u'_jcaruso', 3009230)\n",
      "(u'Dr Kludge', 1898520)\n",
      "(u'TheDutchMan13', 664651)\n",
      "(u'Dr Kludge{import}', 539009)\n",
      "(u'tomthepom', 233832)\n",
      "(u'AJ Riley', 204903)\n",
      "(u'HJUdall', 200963)\n",
      "(u'Adam Martin', 184816)\n",
      "(u'adenium', 168604)\n",
      "(u'MapperMudkip', 152505)\n",
      "\n",
      "Top 10 distinct keys:\n",
      "(u'highway', 134122)\n",
      "(u'natural', 41624)\n",
      "(u'power', 36642)\n",
      "(u'barrier', 34827)\n",
      "(u'amenity', 31600)\n",
      "(u'direction', 29576)\n",
      "(u'crossing', 25805)\n",
      "(u'name', 22110)\n",
      "(u'street', 18169)\n",
      "(u'housenumber', 18030)\n",
      "\n",
      "Top 10 brands keys:\n",
      "(u'Starbucks', 134)\n",
      "(u'Subway', 128)\n",
      "(u'Circle K', 112)\n",
      "(u'Blink', 62)\n",
      "(u'Grid', 58)\n",
      "(u'Wells Fargo', 53)\n",
      "(u'CVS Pharmacy', 52)\n",
      "(u'T-Mobile', 51)\n",
      "(u'Little Caesars', 47)\n",
      "(u'Walmart', 42)\n",
      "\n",
      "Top 10 cuisines:\n",
      "(u'pizza', 160)\n",
      "(u'mexican', 152)\n",
      "(u'american', 62)\n",
      "(u'chinese', 46)\n",
      "(u'sushi', 44)\n",
      "(u'italian', 43)\n",
      "(u'thai', 40)\n",
      "(u'asian', 40)\n",
      "(u'japanese', 24)\n",
      "(u'vietnamese', 20)\n"
     ]
    }
   ],
   "source": [
    "conn=sqlite3.connect('phoenix.db')\n",
    "conn.text_factory = lambda x: unicode(x, 'utf-8', 'ignore')\n",
    "cur = conn.cursor() \n",
    "query='select count(id) from nodes; '\n",
    "total_rows=0\n",
    "result=cur.execute(query)\n",
    "for row in result:\n",
    "    print 'Nodes in database:',  row[0]\n",
    "    total_rows+=row[0]\n",
    "\n",
    "query='select count(id) from ways;'\n",
    "\n",
    "result = cur.execute(query)\n",
    "for row in result:\n",
    "    print 'Ways in database:',  row[0]\n",
    "    total_rows+=row[0]\n",
    "    \n",
    "query='select count(id) from nodes_tags;'\n",
    "\n",
    "result = cur.execute(query)\n",
    "for row in result:\n",
    "    print 'Nodes Tags in database:',  row[0]\n",
    "    total_rows+=row[0]\n",
    "    \n",
    "query='select count(id) from ways_nodes;'\n",
    "\n",
    "result = cur.execute(query)\n",
    "for row in result:\n",
    "    print 'Ways Nodes in database:',  row[0]\n",
    "    total_rows+=row[0]\n",
    "    \n",
    "query='select count(id) from ways_tags;'\n",
    "\n",
    "result = cur.execute(query)\n",
    "for row in result:\n",
    "    print 'Ways Tags in database:',  row[0]\n",
    "    total_rows+=row[0]\n",
    "\n",
    "print '\\nTotal Rows in database:\\033[1m', total_rows, \"\\033[0m\"\n",
    "\n",
    "    \n",
    "query='select count(distinct(user)) from (select user from nodes union all select user from ways);'\n",
    "result=cur.execute(query)\n",
    "for row in result:\n",
    "    print '\\nTotal users that contributed: ', row[0]\n",
    "    \n",
    "query='select user, count(*) from nodes group by user order by count(*) desc limit 10;'\n",
    "print '\\nThe top 10 contributors:'\n",
    "for row in cur.execute(query):\n",
    "    print (row)\n",
    "    \n",
    "query='SELECT DISTINCT key, Count(*) AS [Count] FROM nodes_tags GROUP BY nodes_tags.key ORDER BY Count(*) DESC limit 10;'\n",
    "\n",
    "result=cur.execute(query)\n",
    "print '\\nTop 10 distinct keys:'\n",
    "for row in result:\n",
    "    print (row)\n",
    "    \n",
    "query=\"SELECT DISTINCT value, Count(*) AS [Count] FROM nodes_tags GROUP BY value, key HAVING (((key)='brand')) ORDER BY Count(*) DESC limit 10;\"\n",
    "\n",
    "result=cur.execute(query)\n",
    "print '\\nTop 10 brands keys:'\n",
    "for row in result:\n",
    "    print (row)\n",
    "    \n",
    "query=\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i ON nodes_tags.id=i.id WHERE nodes_tags.key='cuisine' GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 10;\"\n",
    "\n",
    "result=cur.execute(query)\n",
    "print '\\nTop 10 cuisines:'\n",
    "for row in result:\n",
    "    print (row)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonproject",
   "language": "python",
   "name": "pythonproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
